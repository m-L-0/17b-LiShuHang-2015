{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vbuo/.linuxbrew/Cellar/python3/3.6.3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "# 设计一个类，用于读取tfrecord文件和对训练集验证集的批量处理\n",
    "class File:\n",
    "    # 读取tfrecord文件\n",
    "    def readtfrecord(data_type='train', batch_size=10):\n",
    "        filename_queue = tf.train.string_input_producer(\n",
    "            ['/home/vbuo/m-L-1/' + data_type + '.tfrecords'])\n",
    "        # 读取并解析一个tfrecord\n",
    "        reader = tf.TFRecordReader()\n",
    "        _, serialized_example = reader.read(filename_queue)\n",
    "        features = tf.parse_single_example(\n",
    "            serialized_example,\n",
    "            features={\n",
    "                'label': tf.FixedLenFeature([], tf.int64),\n",
    "                'img_raw': tf.FixedLenFeature([], tf.string),\n",
    "            })\n",
    "        image = tf.decode_raw(features['img_raw'], tf.uint8)\n",
    "        image = tf.reshape(image, [1152])\n",
    "        image = tf.cast(image, tf.float32) / 255\n",
    "        label = tf.cast(features['label'], tf.int64)\n",
    "        img_batch, l_batch = tf.train.shuffle_batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            capacity=500,\n",
    "            min_after_dequeue=0)\n",
    "        return img_batch, l_batch\n",
    "\n",
    "\n",
    "    # 数据处理\n",
    "    def read_tfrecord(data_type, num):\n",
    "        img_b = np.empty([num, 1152])\n",
    "        lab = np.empty([num, 34])\n",
    "        img, l = File.readtfrecord(data_type, num)\n",
    "        with tf.Session() as sess:\n",
    "            init_op = tf.global_variables_initializer()\n",
    "            sess.run(init_op)\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(coord=coord)\n",
    "            img, l = sess.run([img, l])\n",
    "            for i in range(num):\n",
    "                img_b[i] = img[i]\n",
    "                lab[i] = tf.one_hot(l[i], depth=34).eval()\n",
    "                if i % 100 == 0:\n",
    "                    print(i)\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "        return img_b, lab\n",
    "\n",
    "\n",
    "#定义存储地址与名称\n",
    "CNN = '/home/vbuo/m-L-1/save'\n",
    "cnn = 'License_plate'\n",
    "\n",
    "\n",
    "# 权值初始化\n",
    "def weight_variable(shape):\n",
    "    # 用正态分布来初始化权值\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    # 本例中用relu激活函数，所以用一个很小的正偏置较好\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial) \n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "    #定义卷积层\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    # 定义池化层\n",
    "    return tf.nn.max_pool(\n",
    "        x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# min_next_batch_tfr(随机批次载入数据)\n",
    "def min_next_batch_tfr(image, label, num=50, num1=500):\n",
    "    images = np.zeros((num, 1152))\n",
    "    labels = np.zeros((num, 34))\n",
    "    for i in range(num):\n",
    "        temp = random.randint(0, num1 - 1)\n",
    "        images[i, :] = image[temp]\n",
    "        labels[i, :] = label[temp]\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 1152])\n",
    "y_ = tf.placeholder(tf.float32, [None, 34])\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "# 第一层卷积: 3×3×1卷积核32个 [3，3，1，32],conv1.shape=[-1, 48, 24, 32],学习32种特征\n",
    "W_conv1 = weight_variable([3, 3, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "# 格式转换\n",
    "x_image = tf.reshape(x, [-1, 48, 24, 1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "# 第一个pooling 层[-1, 48, 24, 32]->[-1, 24, 12, 32]\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# 第二层卷积: 3×3×32卷积核64个 [3，3，32，64],conv2.shape=[-1, 24, 12, 64]\n",
    "W_conv2 = weight_variable([3, 3, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "# 第二个pooling 层,[-1, 24, 12, 64]->[-1, 12, 6, 64]\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# 第三层卷积: 3×3×64卷积核96个 [3，3，64，96],conv3.shape=[-1, 12, 6, 96]\n",
    "W_conv3 = weight_variable([3, 3, 64, 96])\n",
    "b_conv3 = bias_variable([96])\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "# 第三个pooling 层,[-1, 14, 6, 64]->[-1, 6, 3, 96]\n",
    "h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "# flatten层，[-1, 6, 3, 96]->[-1, 6*3*96],即每个样本得到一个6*3*96维的样本\n",
    "W_fc1 = weight_variable([6 * 3 * 96, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool3, [-1, 6 * 3 * 96])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "# 使用drop out防止过拟合（正则化）\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# 输出层，输入1024维，输出34维，即0~33分类\n",
    "W_fc2 = weight_variable([1024, 34])\n",
    "b_fc2 = bias_variable([34])\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "saver = tf.train.Saver(max_to_keep=1)\n",
    "\n",
    "# 损失函数，交叉熵\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n",
    "# 使用adam优化\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "# 准确度计算\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "x_train, y_train = File.read_tfrecord('train', 5000)\n",
    "x_test, y_test = File.read_tfrecord('test', 1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/vbuo/m-L-1/save/License_plate-0\n",
      "step 0, validating accuracy 0.218667, loss is 9369.18\n",
      "step 100, validating accuracy 0.498667, loss is 3325.78\n",
      "step 200, validating accuracy 0.703333, loss is 2265.63\n",
      "step 300, validating accuracy 0.828, loss is 1485.36\n",
      "step 400, validating accuracy 0.877333, loss is 1107.08\n",
      "step 500, validating accuracy 0.92, loss is 814.478\n",
      "step 600, validating accuracy 0.928667, loss is 653.242\n",
      "step 700, validating accuracy 0.942667, loss is 532.134\n",
      "step 800, validating accuracy 0.955333, loss is 432.614\n",
      "step 900, validating accuracy 0.956, loss is 407.923\n",
      "step 1000, validating accuracy 0.962667, loss is 359.49\n",
      "step 1100, validating accuracy 0.968, loss is 313.368\n",
      "step 1200, validating accuracy 0.960667, loss is 317.624\n",
      "step 1300, validating accuracy 0.968667, loss is 277.189\n",
      "step 1400, validating accuracy 0.966667, loss is 259.535\n",
      "step 1500, validating accuracy 0.966667, loss is 284.165\n",
      "step 1600, validating accuracy 0.972667, loss is 244.768\n",
      "step 1700, validating accuracy 0.976, loss is 226.004\n",
      "step 1800, validating accuracy 0.974, loss is 234.988\n",
      "step 1900, validating accuracy 0.976667, loss is 224.823\n",
      "step 2000, validating accuracy 0.98, loss is 212.438\n",
      "step 2100, validating accuracy 0.977333, loss is 215.218\n",
      "step 2200, validating accuracy 0.980667, loss is 203.076\n",
      "step 2300, validating accuracy 0.978667, loss is 216.278\n",
      "step 2400, validating accuracy 0.978, loss is 197.234\n",
      "step 2500, validating accuracy 0.980667, loss is 208.036\n",
      "step 2600, validating accuracy 0.980667, loss is 211.133\n",
      "step 2700, validating accuracy 0.979333, loss is 207.988\n",
      "[9369.1758, 3325.7837, 2265.6323, 1485.3601, 1107.0846, 814.47797, 653.24219, 532.13391, 432.61389, 407.92267, 359.49039, 313.36835, 317.62415, 277.18878, 259.53534, 284.1651, 244.76834, 226.00401, 234.98782, 224.82254, 212.43825, 215.21756, 203.07613, 216.27792, 197.23447, 208.03641, 211.13297, 207.98798]\n",
      "197.234\n"
     ]
    }
   ],
   "source": [
    "# 启动多线程\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    step = 0\n",
    "    j = 0\n",
    "    losslist = []\n",
    "    minloss = 100000\n",
    "    # 若模型存在，自动加载模型进会话\n",
    "    ckpt = tf.train.latest_checkpoint(CNN)\n",
    "    if ckpt:\n",
    "        saver.restore(sess=sess, save_path=ckpt)\n",
    "        step = int(ckpt[len(os.path.join(CNN, cnn)) + 1:])\n",
    "    ckptname = os.path.join(CNN, cnn)\n",
    "\n",
    "    # 开启线程\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    # 训练\n",
    "    for i in range(4000):\n",
    "        batch = min_next_batch_tfr(x_train, y_train, 50, 5000)\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "        # 每一百次用验证集测试一次\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy, loss = sess.run(\n",
    "                [accuracy, cross_entropy],\n",
    "                feed_dict={x: x_test,\n",
    "                           y_: y_test,\n",
    "                           keep_prob: 1})\n",
    "            print(\"step %d, validating accuracy %g, loss is %g\" %\n",
    "                  (i, train_accuracy, loss))\n",
    "            losslist.append(loss)\n",
    "        # 保存损失最低的模型\n",
    "        if minloss > loss:\n",
    "            minloss = loss\n",
    "            saver.save(sess, ckptname, global_step=i)\n",
    "        if losslist[-1] > minloss and losslist[-2] > minloss and losslist[-3] > minloss:\n",
    "            break\n",
    "\n",
    "    # 损失函数列表\n",
    "    print(losslist)\n",
    "    print(minloss)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
